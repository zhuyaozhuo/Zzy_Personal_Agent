import os
import sys

# å°†configç›®å½•æ·»åŠ åˆ°è·¯å¾„
config_dir = os.path.join(os.path.dirname(__file__), '..', 'config')
sys.path.insert(0, config_dir)

from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import yt_dlp
import json
import re
from datetime import datetime
from docx import Document
from io import BytesIO

app = Flask(__name__)
CORS(app)

DATA_DIR = os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'youtube')
os.makedirs(DATA_DIR, exist_ok=True)

def extract_video_id(url):
    patterns = [
        r'(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/|youtube\.com\/v\/|youtube\.com\/shorts\/)([a-zA-Z0-9_-]{11})'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None

def get_video_info(video_id):
    url = f'https://www.youtube.com/watch?v={video_id}'
    
    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'skip_download': True,
    }
    
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        try:
            info = ydl.extract_info(url, download=False)
            
            video_data = {
                'video_id': video_id,
                'title': info.get('title', ''),
                'url': url,
                'thumbnail': info.get('thumbnail', ''),
                'channel': info.get('channel', ''),
                'channel_url': info.get('channel_url', ''),
                'views': info.get('view_count', 0),
                'duration': info.get('duration', 0),
                'published': info.get('upload_date', ''),
                'description': info.get('description', ''),
                'view_count': info.get('view_count', 0),
                'like_count': info.get('like_count', 0),
                'comment_count': info.get('comment_count', 0),
                'channel_id': info.get('channel_id', ''),
                'channel_follower_count': info.get('channel_follower_count', 0),
                'upload_date': info.get('upload_date', ''),
                'categories': info.get('categories', []),
                'tags': info.get('tags', []),
            }
            
            return video_data
        except Exception as e:
            print(f"Error fetching video info: {e}")
            return None

def get_transcript(video_id, language='en'):
    url = f'https://www.youtube.com/watch?v={video_id}'
    
    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'skip_download': True,
        'writesubtitles': True,
        'writeautomaticsub': True,
        'subtitleslangs': [language],
    }
    
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        try:
            info = ydl.extract_info(url, download=False)
            
            if 'subtitles' in info and language in info['subtitles']:
                subtitle_url = info['subtitles'][language][0]['url']
            elif 'automatic_captions' in info and language in info['automatic_captions']:
                subtitle_url = info['automatic_captions'][language][0]['url']
            else:
                # å°è¯•æ¨¡ç³ŠåŒ¹é…è¯­è¨€
                subs = info.get('subtitles', {}) or {}
                auto_subs = info.get('automatic_captions', {}) or {}
                
                # æŸ¥æ‰¾åŒ…å«è¯¥è¯­è¨€å‰ç¼€çš„å­—å¹•
                for key in list(subs.keys()) + list(auto_subs.keys()):
                    if key.startswith(language.split('-')[0]):
                        subtitle_url = (subs.get(key) or auto_subs.get(key))[0]['url']
                        break
                else:
                    return None
            
            import requests
            response = requests.get(subtitle_url)
            return response.text
        except Exception as e:
            print(f"Error fetching transcript: {e}")
            return None

def parse_srt_to_text(srt_content):
    import json
    
    if not srt_content:
        return ""
    
    try:
        data = json.loads(srt_content)
        
        if 'events' in data:
            text_lines = []
            for event in data.get('events', []):
                segs = event.get('segs', [])
                for seg in segs:
                    if 'utf8' in seg:
                        text = seg['utf8'].strip()
                        if text:
                            text_lines.append(text)
            return ' '.join(text_lines)
    except (json.JSONDecodeError, TypeError):
        pass
    
    lines = srt_content.split('\n')
    text_lines = []
    
    for line in lines:
        line = line.strip()
        if line and not line.isdigit() and '-->' not in line:
            text_lines.append(line)
    
    return '\n'.join(text_lines)

def format_srt_time(seconds):
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds * 1000) % 1000)
    
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

def create_srt_content(transcript_data):
    if isinstance(transcript_data, str):
        return transcript_data
    
    srt_content = []
    for i, entry in enumerate(transcript_data, 1):
        start_time = entry.get('start', 0)
        duration = entry.get('duration', 0)
        text = entry.get('text', '')
        
        srt_content.append(str(i))
        srt_content.append(f"{format_srt_time(start_time)} --> {format_srt_time(start_time + duration)}")
        srt_content.append(text)
        srt_content.append('')
    
    return '\n'.join(srt_content)

def create_docx(transcript_text, title, video_info=None, include_summary=True):
    doc = Document()
    
    doc.add_heading(title, 0)
    
    if video_info and include_summary:
        doc.add_heading('ğŸ“º è§†é¢‘ä¿¡æ¯', level=1)
        
        info_data = [
            ('ğŸ“… å‘å¸ƒæ—¶é—´', video_info.get('published', 'æœªçŸ¥')),
            ('ğŸ”— è§†é¢‘é“¾æ¥', video_info.get('url', 'æœªçŸ¥')),
            ('ğŸ“º å‘å¸ƒè´¦å·', video_info.get('channel', 'æœªçŸ¥')),
            ('ğŸ‘ï¸ è§‚çœ‹æ¬¡æ•°', f"{video_info.get('view_count', 0):,}"),
            ('ğŸ‘ ç‚¹èµæ•°é‡', f"{video_info.get('like_count', 0):,}"),
            ('â±ï¸ è§†é¢‘æ—¶é•¿', f"{video_info.get('duration', 0)//60} åˆ†é’Ÿ"),
        ]
        
        for label, value in info_data:
            p = doc.add_paragraph()
            p.add_run(f"{label}: ").bold = True
            p.add_run(str(value))
        
        doc.add_paragraph('')
        
        doc.add_heading('ğŸ“ å†…å®¹æ‘˜è¦', level=1)
        
        doc.add_paragraph('ã€è§†é¢‘ç®€ä»‹ã€‘')
        description = video_info.get('description', 'æ— ')
        if len(description) > 500:
            description = description[:500] + '...'
        doc.add_paragraph(description)
        
        doc.add_paragraph('')
        doc.add_paragraph('ã€æ ¸å¿ƒè§‚ç‚¹ã€‘')
        doc.add_paragraph('ï¼ˆä»¥ä¸‹ä¸ºAIæ ¹æ®å­—å¹•å†…å®¹è‡ªåŠ¨æå–ï¼Œä»…ä¾›å‚è€ƒï¼‰')
        
        use_gpt = bool(os.environ.get('OPENAI_API_KEY', '') or os.environ.get('SILICONFLOW_API_KEY', ''))
        
        # ä¹Ÿæ£€æŸ¥é…ç½®æ–‡ä»¶
        if not use_gpt:
            try:
                from api_config import SILICONFLOW_API_KEY
                use_gpt = bool(SILICONFLOW_API_KEY)
            except:
                pass
        
        keywords = extract_key_points(transcript_text, use_gpt=use_gpt)
        for i, point in enumerate(keywords[:8], 1):
            doc.add_paragraph(f"{i}. {point}")
        
        doc.add_paragraph('')
        
        doc.add_heading('ğŸ“‹ å­—å¹•å†…å®¹', level=1)
    
    doc.add_paragraph(f'ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
    doc.add_paragraph('')
    
    for line in transcript_text.split('\n'):
        if line.strip():
            doc.add_paragraph(line)
    
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

def extract_key_points(text, use_gpt=False):
    import re
    from collections import Counter
    
    if not text or len(text) < 50:
        return ["å†…å®¹å¤ªçŸ­ï¼Œæ— æ³•æå–æ ¸å¿ƒè§‚ç‚¹"]
    
    # å¦‚æœæœ‰API Keyï¼Œä¼˜å…ˆä½¿ç”¨AIç”Ÿæˆæ ¸å¿ƒè§‚ç‚¹
    if use_gpt:
        ai_points = generate_gpt_summary(text, [])
        if ai_points and ai_points[0] not in ["å†…å®¹å¤ªçŸ­ï¼Œæ— æ³•æå–æ ¸å¿ƒè§‚ç‚¹", "æœªèƒ½æå–æ ¸å¿ƒè§‚ç‚¹"]:
            return ai_points
    
    text = re.sub(r'\s+', ' ', text)
    
    # æå–å…³é”®ä¸»é¢˜
    themes = {
        'ä¸­ç¾å…³ç³»': [],
        'å°æ¹¾é—®é¢˜': [],
        'å·ä¹ ä¼š': [],
        'æ™®äº¬/ä¿„ç½—æ–¯': [],
        'ç»æµè´¸æ˜“': [],
        'å›½é™…å±€åŠ¿': []
    }
    
    # å…³é”®æ¨¡å¼åŒ¹é…
    theme_patterns = {
        'ä¸­ç¾å…³ç³»': ['ä¸­ç¾', 'ä¸­ç¾å…³ç³»', 'ä¸­å›½å¤§é™†', 'ç¾å›½', 'ç‰¹æœ—æ™®', 'ä¸­å›½'],
        'å°æ¹¾é—®é¢˜': ['å°æ¹¾', 'å°æµ·', 'å¯¹å°å†›å”®', 'å†›å”®', 'ä¸€ä¸­', 'ä¸€ä¸ªä¸­å›½'],
        'å·ä¹ ä¼š': ['å·ä¹ ä¼š', 'ä¹ è¿‘å¹³', 'ç‰¹æœ—æ™®', 'åŒ—äº¬', 'ä¼šé¢', 'è®¿é—®', 'å³°ä¼š'],
        'æ™®äº¬/ä¿„ç½—æ–¯': ['æ™®äº¬', 'ä¿„ç½—æ–¯', 'ä¿„ç½—', 'æ™®ä¸'],
        'ç»æµè´¸æ˜“': ['ç¨€åœŸ', 'å¤§è±†', 'çŸ³æ²¹', 'å¤©ç„¶æ°”', 'è´¸æ˜“', 'å…³ç¨', 'ç»æµ', 'è´­ä¹°'],
        'å›½é™…å±€åŠ¿': ['ä¼Šæœ—', 'å°åº¦', 'æ—¥æœ¬', 'é€‰ä¸¾', 'æˆ˜äº‰', 'å’Œè°ˆ']
    }
    
    # æ™ºèƒ½æ–­å¥
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!?\n]+', text)
    processed = []
    for s in sentences:
        s = s.strip()
        if not s or len(s) < 6:
            continue
        # é•¿å¥æŒ‰é€—å·æ‹†åˆ†
        if len(s) > 60 and 'ï¼Œ' in s:
            parts = s.split('ï¼Œ')
            for p in parts:
                p = p.strip()
                if len(p) > 12:
                    processed.append(p)
        else:
            processed.append(s)
    
    sentences = processed
    
    # å¯¹æ¯ä¸ªä¸»é¢˜æ‰¾ç›¸å…³å¥å­
    for theme, keywords in theme_patterns.items():
        for sent in sentences:
            for kw in keywords:
                if kw in sent and len(sent) > 15:
                    if sent not in themes[theme]:
                        themes[theme].append(sent)
                    break
    
    # æå–é«˜åˆ†å¥å­
    high_value = ['å…³é”®', 'é‡è¦', 'æ ¸å¿ƒ', 'ä¸»è¦', 'åŸå› ', 'å› ä¸º', 'ç»“è®º', 'æ‰€ä»¥', 'å› æ­¤', 
                  'è®¤ä¸º', 'é¢„æµ‹', 'ä¼°è®¡', 'åˆ†æ', 'æ˜¾ç¤º', 'è¡¨æ˜', 'è¶‹åŠ¿', 'æœªæ¥', 'å¿…é¡»']
    
    scored = []
    filler = ['å—¯', 'å•Š', 'è¿™ä¸ª', 'é‚£ä¸ª', 'å¥½å§', 'æ˜¯çš„']
    
    for i, sent in enumerate(sentences):
        score = 0
        length = len(sent)
        
        if 15 <= length <= 70:
            score += 2
        if length > 100:
            score -= 1
        
        for hv in high_value:
            if hv in sent:
                score += 2
        
        for f in filler:
            if sent.startswith(f):
                score -= 2
                break
        
        if i < 5:
            score += 2
        if i > len(sentences) * 0.8:
            score += 2
        
        if score > 0:
            scored.append((sent, score))
    
    scored.sort(key=lambda x: x[1], reverse=True)
    
    # æ„å»ºé«˜è´¨é‡æ‘˜è¦
    result = []
    used = set()
    
    # ä¼˜å…ˆä»ä¸»é¢˜ç›¸å…³å¥å­ä¸­é€‰æ‹©
    for theme, theme_sents in themes.items():
        if len(result) >= 6:
            break
        for sent in theme_sents[:3]:
            if len(result) >= 6:
                break
            # æ¸…ç†
            cleaned = sent.strip()
            for f in filler:
                if cleaned.startswith(f):
                    cleaned = cleaned[len(f):].strip()
                    break
            
            if not cleaned or len(cleaned) < 12:
                continue
            
            key = cleaned[:20]
            if key in used:
                continue
            
            # ç²¾ç®€
            if len(cleaned) > 45:
                for p in 'ã€‚ï¼›,':
                    if p in cleaned[20:]:
                        idx = cleaned.index(p, 20)
                        if idx < 42:
                            cleaned = cleaned[:idx+1]
                            break
                else:
                    cleaned = cleaned[:42] + '...'
            
            if len(cleaned) > 10:
                result.append(cleaned)
                used.add(key)
    
    # è¡¥å……é«˜åˆ†å¥å­
    for sent, score in scored:
        if len(result) >= 8:
            break
        
        cleaned = sent.strip()
        for f in filler:
            if cleaned.startswith(f):
                cleaned = cleaned[len(f):].strip()
                break
        
        if len(cleaned) < 12:
            continue
        
        key = cleaned[:20]
        if key in used:
            continue
        
        if len(cleaned) > 45:
            cleaned = cleaned[:42] + '...'
        
        result.append(cleaned)
        used.add(key)
    
    # åå¤„ç† - åˆæˆæ›´ç²¾ç‚¼çš„è§‚ç‚¹
    final_points = []
    for point in result[:8]:
        # å»é™¤å¼€å¤´æ— æ„ä¹‰è¯
        point = re.sub(r'^(?:å—¯|å•Š|è¿™ä¸ª|é‚£ä¸ª|é‚£ä¹ˆ|å°±æ˜¯|å…¶å®|å¥½å§),*\s*', '', point)
        point = point.strip()
        if len(point) > 8:
            final_points.append(point)
    
    return final_points[:8] if final_points else ["æœªèƒ½æå–æ ¸å¿ƒè§‚ç‚¹"]

def generate_gpt_summary(text, fallback_points):
    """ä½¿ç”¨AIç”Ÿæˆé«˜è´¨é‡æ‘˜è¦ - æ”¯æŒç¡…åŸºæµåŠ¨å’ŒOpenAI"""
    try:
        import os
        import sys
        import requests
        import re
        
        # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è·å–ï¼Œå…¶æ¬¡ä»é…ç½®æ–‡ä»¶è¯»å–
        silicon_key = os.environ.get('SILICONFLOW_API_KEY', '')
        openai_key = os.environ.get('OPENAI_API_KEY', '')
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–
        if not silicon_key and not openai_key:
            try:
                from api_config import SILICONFLOW_API_KEY
                silicon_key = SILICONFLOW_API_KEY or ''
            except:
                pass
        
        api_key = silicon_key or openai_key
        if not api_key:
            return fallback_points
        
        # æˆªå–æ–‡æœ¬å‰8000å­—ç¬¦ï¼ˆå‡å°‘ä»¥æé«˜å“åº”é€Ÿåº¦ï¼‰
        text_sample = text[:8000]
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†æç‚¼ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹è§†é¢‘å­—å¹•å†…å®¹ï¼Œæå–6-8ä¸ªæ ¸å¿ƒè§‚ç‚¹ã€‚

è¦æ±‚ï¼š
1. æ¯ä¸ªè§‚ç‚¹è¦ç”¨ä¸€å¥è¯æ¦‚æ‹¬ï¼Œ25-45å­—
2. è§‚ç‚¹è¦æœ‰ä¿¡æ¯ä»·å€¼ï¼Œèƒ½æ¦‚æ‹¬è§†é¢‘ä¸»è¦å†…å®¹
3. åŒ…å«å…³é”®äººç‰©ã€äº‹ä»¶ã€æ•°æ®
4. ä½¿ç”¨ç®€æ´æœ‰åŠ›çš„ä¸­æ–‡è¡¨è¾¾
5. è§‚ç‚¹è¦å¤šæ ·åŒ–ï¼Œè¦†ç›–ä¸åŒä¸»é¢˜

å­—å¹•å†…å®¹ï¼š
{text_sample}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆåªéœ€6-8æ¡ï¼Œä¸è¦æ›´å¤šï¼‰ï¼š
1. [æ ¸å¿ƒè§‚ç‚¹1]
2. [æ ¸å¿ƒè§‚ç‚¹2]
3. [æ ¸å¿ƒè§‚ç‚¹3]
...
"""
        
        # åˆ¤æ–­ä½¿ç”¨å“ªä¸ªAPI
        if silicon_key:
            base_url = "https://api.siliconflow.cn/v1"
            model = "Qwen/QwQ-32B"
        else:
            base_url = "https://api.openai.com/v1"
            model = "gpt-3.5-turbo"
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': model,
            'messages': [
                {'role': 'user', 'content': prompt}
            ],
            'temperature': 0.7,
            'max_tokens': 1000
        }
        
        # æ·»åŠ é‡è¯•æœºåˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    f'{base_url}/chat/completions',
                    headers=headers,
                    json=data,
                    timeout=120
                )
                
                if response.status_code == 200:
                    result = response.json()
                    content = result['choices'][0]['message']['content']
                    
                    # è§£æAIè¾“å‡º
                    points = []
                    for line in content.split('\n'):
                        line = line.strip()
                        if line and (line[0].isdigit() or line.startswith('-') or line.startswith('â€¢')):
                            # å»æ‰åºå·
                            cleaned = re.sub(r'^[0-9]+[.ã€)\]ã€‘\s]+', '', line)
                            cleaned = re.sub(r'^[-â€¢]\s*', '', cleaned)
                            cleaned = cleaned.strip()
                            if cleaned and len(cleaned) > 10:
                                points.append(cleaned)
                    
                    if points:
                        return points[:8]
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"AI summary attempt {attempt + 1} failed, retrying: {e}")
                    import time
                    time.sleep(2)
                else:
                    raise e
        
        return fallback_points
    except Exception as e:
        print(f"AI summary error: {e}")
        return fallback_points

def smart_sentence_split(text):
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!?]+', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    return '\n'.join(sentences)

def translate_text(text, target_lang='zh-CN'):
    try:
        import requests
        
        lang_map = {
            'zh-CN': 'zh-CN',
            'zh-TW': 'zh-TW', 
            'en': 'en',
            'ja': 'ja',
            'ko': 'ko'
        }
        
        dest = lang_map.get(target_lang, 'zh-CN')
        
        url = "https://translate.googleapis.com/translate_a/single"
        params = {
            'client': 'gtx',
            'sl': 'auto',
            'tl': dest,
            'dt': 't',
            'q': text[:5000]
        }
        
        response = requests.get(url, params=params, timeout=30)
        result = response.json()
        
        translated = ''.join([item[0] for item in result[0] if item[0]])
        
        if len(text) > 5000:
            translated += translate_text(text[5000:], target_lang)
        
        return translated
    except Exception as e:
        print(f"Translation error: {e}")
        return text

@app.route('/api/video/<video_id>')
def get_video(video_id):
    video_data = get_video_info(video_id)
    
    if video_data:
        return jsonify(video_data)
    else:
        return jsonify({'error': 'Failed to fetch video info'}), 404

@app.route('/api/download', methods=['POST'])
def download():
    data = request.json
    video_id = data.get('video_id')
    format_type = data.get('format', 'txt')
    language = data.get('language', 'en')
    translate = data.get('translate', 'none')
    sentence_mode = data.get('sentence', 'auto')
    
    if not video_id:
        return jsonify({'error': 'Video ID is required'}), 400
    
    srt_content = get_transcript(video_id, language)
    
    if not srt_content:
        srt_content = get_transcript(video_id, 'en')
    
    if not srt_content:
        # æ£€æŸ¥æ˜¯å¦æœ‰è‡ªåŠ¨å­—å¹•
        try:
            import yt_dlp
            url = f'https://www.youtube.com/watch?v={video_id}'
            ydl = yt_dlp.YoutubeDL({'quiet': True})
            info = ydl.extract_info(url, download=False)
            auto_subs = info.get('automatic_captions', {}) or {}
            manual_subs = info.get('subtitles', {}) or {}
            
            if not auto_subs and not manual_subs:
                return jsonify({
                    'error': 'è¯¥è§†é¢‘æ²¡æœ‰å­—å¹•',
                    'hint': 'è¯·é€‰æ‹©å…¶ä»–æœ‰å­—å¹•çš„è§†é¢‘'
                }), 404
            else:
                return jsonify({
                    'error': 'æ‰€é€‰è¯­è¨€å­—å¹•ä¸å¯ç”¨',
                    'available_languages': list(auto_subs.keys()) + list(manual_subs.keys()),
                    'hint': 'å°è¯•é€‰æ‹©å…¶ä»–è¯­è¨€'
                }), 404
        except:
            return jsonify({'error': 'è·å–å­—å¹•å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•'}), 404
    
    transcript_text = parse_srt_to_text(srt_content)
    
    if translate != 'none':
        transcript_text = translate_text(transcript_text, translate)
    
    if sentence_mode == 'auto':
        transcript_text = smart_sentence_split(transcript_text)
    
    video_info = get_video_info(video_id)
    title = video_info.get('title', 'subtitle') if video_info else 'subtitle'
    
    def generate_summary_text(transcript_text, video_info):
        lines = []
        lines.append("=" * 60)
        lines.append(title)
        lines.append("=" * 60)
        lines.append("")
        lines.append("ã€è§†é¢‘ä¿¡æ¯ã€‘")
        lines.append(f"å‘å¸ƒæ—¶é—´: {video_info.get('published', 'æœªçŸ¥')}")
        lines.append(f"è§†é¢‘é“¾æ¥: {video_info.get('url', 'æœªçŸ¥')}")
        lines.append(f"å‘å¸ƒè´¦å·: {video_info.get('channel', 'æœªçŸ¥')}")
        lines.append(f"è§‚çœ‹æ¬¡æ•°: {video_info.get('view_count', 0):,}")
        lines.append(f"ç‚¹èµæ•°é‡: {video_info.get('like_count', 0):,}")
        lines.append(f"è§†é¢‘æ—¶é•¿: {video_info.get('duration', 0)//60} åˆ†é’Ÿ")
        lines.append("")
        lines.append("ã€è§†é¢‘ç®€ä»‹ã€‘")
        description = video_info.get('description', 'æ— ')
        if len(description) > 500:
            description = description[:500] + '...'
        lines.append(description)
        lines.append("")
        lines.append("ã€æ ¸å¿ƒè§‚ç‚¹ã€‘")
        lines.append("ï¼ˆä»¥ä¸‹ä¸ºAIæ ¹æ®å­—å¹•å†…å®¹è‡ªåŠ¨æå–ï¼Œä»…ä¾›å‚è€ƒï¼‰")
        
        use_gpt = bool(os.environ.get('OPENAI_API_KEY', '') or os.environ.get('SILICONFLOW_API_KEY', ''))
        
        # ä¹Ÿæ£€æŸ¥é…ç½®æ–‡ä»¶
        if not use_gpt:
            try:
                from api_config import SILICONFLOW_API_KEY
                use_gpt = bool(SILICONFLOW_API_KEY)
            except:
                pass
        
        keywords = extract_key_points(transcript_text, use_gpt=use_gpt)
        for i, point in enumerate(keywords[:8], 1):
            lines.append(f"{i}. {point}")
        
        lines.append("")
        lines.append("=" * 60)
        lines.append("ã€å­—å¹•å†…å®¹ã€‘")
        lines.append("=" * 60)
        lines.append("")
        lines.append(transcript_text)
        return '\n'.join(lines)
    
    if format_type == 'txt':
        full_content = generate_summary_text(transcript_text, video_info)
        output = BytesIO(full_content.encode('utf-8'))
        output.seek(0)
        return send_file(
            output,
            mimetype='text/plain',
            as_attachment=True,
            download_name=f'{title[:50]}_subtitle.txt'
        )
    
    elif format_type == 'srt':
        output = BytesIO(srt_content.encode('utf-8'))
        output.seek(0)
        return send_file(
            output,
            mimetype='text/plain',
            as_attachment=True,
            download_name=f'{title[:50]}_subtitle.srt'
        )
    
    elif format_type == 'docx':
        docx_buffer = create_docx(transcript_text, title, video_info)
        response = send_file(
            docx_buffer,
            mimetype='application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            as_attachment=True,
            download_name=f'{title[:50]}_subtitle.docx'
        )
        response.headers['Access-Control-Expose-Headers'] = 'Content-Disposition'
        return response
    
    elif format_type == 'json':
        json_data = {
            'video_id': video_id,
            'title': title,
            'transcript': transcript_text,
            'language': language,
            'generated_at': datetime.now().isoformat()
        }
        output = BytesIO(json.dumps(json_data, ensure_ascii=False, indent=2).encode('utf-8'))
        output.seek(0)
        return send_file(
            output,
            mimetype='application/json',
            as_attachment=True,
            download_name=f'{title[:50]}_subtitle.json'
        )
    
    return jsonify({'error': 'Invalid format'}), 400

@app.route('/api/health')
def health():
    return jsonify({'status': 'healthy'})

# ==================== Bç«™ API ====================

def get_bilibili_sessdata():
    """è·å–Bç«™SESSDATA"""
    # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è·å–
    sessdata = os.environ.get('BILIBILI_SESSDATA', '')
    if not sessdata:
        try:
            from api_config import BILIBILI_SESSDATA
            sessdata = BILIBILI_SESSDATA
        except:
            pass
    return sessdata

BILIBILI_SESSDATA = get_bilibili_sessdata()

def get_bilibili_headers():
    """è·å–Bç«™APIè¯·æ±‚å¤´"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
        'Referer': 'https://www.bilibili.com'
    }
    if BILIBILI_SESSDATA:
        headers['Cookie'] = f'SESSDATA={BILIBILI_SESSDATA}'
    return headers

def get_bilibili_video_info(video_type, video_id):
    """è·å–Bç«™è§†é¢‘ä¿¡æ¯"""
    import requests
    
    if video_type == 'bv':
        # é€šè¿‡BVå·è·å–AVå·
        api_url = f"https://api.bilibili.com/x/web-interface/view?bvid={video_id}"
    else:
        # ç›´æ¥ä½¿ç”¨AVå·
        api_url = f"https://api.bilibili.com/x/web-interface/view?aid={video_id}"
    
    headers = get_bilibili_headers()
    
    response = requests.get(api_url, headers=headers)
    data = response.json()
    
    if data.get('code') != 0:
        raise Exception(data.get('message', 'è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥'))
    
    info = data.get('data', {})
    
    # æ ¼å¼åŒ–æ—¶é•¿
    duration = info.get('duration', 0)
    minutes = duration // 60
    seconds = duration % 60
    duration_str = f"{minutes}:{seconds:02d}"
    
    return {
        'video_id': video_id,
        'video_type': video_type,
        'aid': info.get('aid'),
        'bvid': info.get('bvid'),
        'title': info.get('title', ''),
        'description': info.get('desc', ''),
        'thumbnail': info.get('pic', ''),
        'duration': duration_str,
        'author': info.get('owner', {}).get('name', ''),
        'publish_time': info.get('pubdate', 0)
    }

def get_bilibili_subtitle(aid):
    """è·å–Bç«™å¼¹å¹•ï¼ˆä½œä¸ºå­—å¹•ä½¿ç”¨ï¼‰"""
    import requests
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
        'Referer': 'https://www.bilibili.com'
    }
    
    # è·å–è§†é¢‘ä¿¡æ¯ä¸­çš„å­—å¹•åˆ—è¡¨
    view_url = f"https://api.bilibili.com/x/web-interface/view?aid={aid}"
    response = requests.get(view_url, headers=headers)
    data = response.json()
    
    if data.get('code') != 0:
        return None
    
    info = data.get('data', {})
    
    # ä¼˜å…ˆå°è¯•è·å–AIå­—å¹•ï¼ˆéœ€è¦Cookieï¼‰
    if BILIBILI_SESSDATA:
        try:
            player_url = f"https://api.bilibili.com/x/player/wbi/v2?aid={aid}&cid={info.get('cid')}"
            response = requests.get(player_url, headers=get_bilibili_headers())
            player_data = response.json()
            
            if player_data.get('code') == 0:
                subtitle_info = player_data.get('data', {}).get('subtitle', {})
                subtitles_list = subtitle_info.get('subtitles', [])
                
                # æŸ¥æ‰¾AIå­—å¹•
                for sub in subtitles_list:
                    if sub.get('lan', '').startswith('ai-'):
                        subtitle_url = sub.get('subtitle_url', '')
                        if subtitle_url:
                            # å¤„ç†ç›¸å¯¹URL
                            if subtitle_url.startswith('//'):
                                subtitle_url = 'https:' + subtitle_url
                            # è·å–å®Œæ•´çš„å­—å¹•å†…å®¹
                            sub_response = requests.get(subtitle_url)
                            if sub_response.status_code == 200:
                                ai_sub_data = sub_response.json()
                                # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                                return {
                                    'code': 0,
                                    'message': 'success',
                                    'body': [
                                        {
                                            'from': item.get('from', 0),
                                            'to': item.get('to', 0),
                                            'content': item.get('content', '')
                                        }
                                        for item in ai_sub_data.get('body', [])
                                    ]
                                }
        except Exception as e:
            print(f"è·å–AIå­—å¹•å¤±è´¥: {e}")
    
    # å°è¯•è·å–æ™®é€šå­—å¹•
    subtitle_info = info.get('subtitle', {})
    subtitles = subtitle_info.get('subtitles', [])
    
    if subtitles:
        subtitle_data = subtitles[0]
        subtitle_api_url = f"https://comment.bilibili.com/{subtitle_data.get('id')}.json"
        response = requests.get(subtitle_api_url, headers=headers)
        if response.status_code == 200:
            return response.json()
    
    # æ²¡æœ‰å­—å¹•æ—¶ï¼Œä½¿ç”¨å¼¹å¹•ä½œä¸ºæ›¿ä»£
    danmaku_url = f"https://comment.bilibili.com/{aid}.json"
    response = requests.get(danmaku_url, headers=headers)
    if response.status_code != 200:
        return None
    
    # å°†å¼¹å¹•è½¬æ¢ä¸ºå­—å¹•æ ¼å¼
    danmaku_data = response.json()
    body = danmaku_data.get('body', [])
    
    # è½¬æ¢ä¸ºå­—å¹•æ ¼å¼
    converted = {
        'code': 0,
        'message': 'success',
        'ttl': 1,
        'body': [
            {
                'id': item.get('id', 0),
                'mode': item.get('mode', 1),
                'msg': item.get('c', ''),
                'progress': item.get('p', 0),
                'color': item.get('c', '').split(',')[0] if ',' in str(item.get('c', '')) else 'ffffff',
                'from': item.get('p', 0) / 1000 if isinstance(item.get('p'), (int, float)) else 0,
                'to': (item.get('p', 0) / 1000 + 3) if isinstance(item.get('p'), (int, float)) else 3,
                'content': item.get('c', '').split(',')[-1] if ',' in str(item.get('c', '')) else item.get('c', '')
            }
            for item in body[:500]  # é™åˆ¶500æ¡
        ]
    }
    
    return converted

@app.route('/api/bilibili/video/<video_type>/<video_id>')
def get_bilibili_video(video_type, video_id):
    """è·å–Bç«™è§†é¢‘ä¿¡æ¯API"""
    try:
        video_info = get_bilibili_video_info(video_type, video_id)
        return jsonify(video_info)
    except Exception as e:
        return jsonify({'error': str(e)}), 404

@app.route('/api/bilibili/download', methods=['POST'])
def download_bilibili_subtitle():
    """ä¸‹è½½Bç«™å­—å¹•API"""
    data = request.json
    video_id = data.get('video_id')
    video_type = data.get('video_type', 'bv')
    format_type = data.get('format', 'txt')
    language = data.get('language', 'original')
    translate = data.get('translate', 'none')
    
    if not video_id:
        return jsonify({'error': 'Video ID is required'}), 400
    
    try:
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = get_bilibili_video_info(video_type, video_id)
        
        # è·å–å­—å¹•
        subtitle_data = get_bilibili_subtitle(video_info['aid'])
        
        if not subtitle_data:
            return jsonify({
                'error': 'è¯¥è§†é¢‘æ²¡æœ‰å­—å¹•/å¼¹å¹•',
                'hint': 'Bç«™å¤§éƒ¨åˆ†è§†é¢‘æ— å®˜æ–¹å­—å¹•ï¼Œè¯·é€‰æ‹©å…¶ä»–è§†é¢‘ï¼ˆå¦‚æ•™ç¨‹ã€æ¼”è®²ç±»ï¼‰'
            }), 404
        
        # è§£æå­—å¹•å†…å®¹
        subtitles = subtitle_data.get('body', [])
        transcript_text = '\n'.join([item.get('content', '') for item in subtitles])
        
        # ç¿»è¯‘
        if translate != 'none':
            transcript_text = translate_text(transcript_text, translate)
        
        # ç”ŸæˆBç«™ç‰¹æœ‰çš„å†…å®¹æ ¼å¼
        def generate_bilibili_summary_text(video_info, transcript_text):
            lines = []
            lines.append("=" * 60)
            lines.append(video_info['title'])
            lines.append("=" * 60)
            lines.append("")
            lines.append("ã€è§†é¢‘ä¿¡æ¯ã€‘")
            lines.append(f"æ ‡é¢˜: {video_info['title']}")
            lines.append(f"é“¾æ¥: https://www.bilibili.com/video/{video_info.get('bvid', video_id)}")
            lines.append(f"ä½œè€…: {video_info['author']}")
            lines.append(f"æ—¶é•¿: {video_info['duration']}")
            lines.append("")
            lines.append("ã€è§†é¢‘ç®€ä»‹ã€‘")
            description = video_info.get('description', 'æ— ')
            if len(description) > 500:
                description = description[:500] + '...'
            lines.append(description)
            lines.append("")
            lines.append("ã€æ ¸å¿ƒè§‚ç‚¹ã€‘")
            lines.append("ï¼ˆä»¥ä¸‹ä¸ºAIæ ¹æ®å­—å¹•å†…å®¹è‡ªåŠ¨æå–ï¼Œä»…ä¾›å‚è€ƒï¼‰")
            
            use_gpt = bool(os.environ.get('OPENAI_API_KEY', '') or os.environ.get('SILICONFLOW_API_KEY', ''))
            if not use_gpt:
                try:
                    from api_config import SILICONFLOW_API_KEY
                    use_gpt = bool(SILICONFLOW_API_KEY)
                except:
                    pass
            
            keywords = extract_key_points(transcript_text, use_gpt=use_gpt)
            for i, point in enumerate(keywords[:8], 1):
                lines.append(f"{i}. {point}")
            
            lines.append("")
            lines.append("=" * 60)
            lines.append("ã€å­—å¹•å†…å®¹ã€‘")
            lines.append("=" * 60)
            lines.append("")
            lines.append(transcript_text)
            return '\n'.join(lines)
        
        def generate_bilibili_srt(subtitles):
            lines = []
            for i, item in enumerate(subtitles, 1):
                content = item.get('content', '').replace('\n', ' ')
                from_time = item.get('from', 0)
                to_time = item.get('to', 0)
                
                hours = int(from_time // 3600)
                minutes = int((from_time % 3600) // 60)
                secs = int(from_time % 60)
                millisecs = int((from_time % 1) * 1000)
                from_str = f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
                
                hours = int(to_time // 3600)
                minutes = int((to_time % 3600) // 60)
                secs = int(to_time % 60)
                millisecs = int((to_time % 1) * 1000)
                to_str = f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
                
                lines.append(str(i))
                lines.append(f"{from_str} --> {to_str}")
                lines.append(content)
                lines.append("")
            
            return '\n'.join(lines)
        
        # ç”Ÿæˆè¾“å‡º
        if format_type == 'txt':
            full_content = generate_bilibili_summary_text(video_info, transcript_text)
            output = BytesIO(full_content.encode('utf-8'))
            output.seek(0)
            return send_file(
                output,
                mimetype='text/plain',
                as_attachment=True,
                download_name=f"{video_info['title'][:50]}_subtitle.txt"
            )
        elif format_type == 'srt':
            srt_content = generate_bilibili_srt(subtitles)
            output = BytesIO(srt_content.encode('utf-8'))
            output.seek(0)
            return send_file(
                output,
                mimetype='text/plain',
                as_attachment=True,
                download_name=f"{video_info['title'][:50]}_subtitle.srt"
            )
        elif format_type == 'json':
            json_content = json.dumps({
                'video': video_info,
                'subtitles': subtitles,
                'transcript': transcript_text
            }, ensure_ascii=False, indent=2)
            output = BytesIO(json_content.encode('utf-8'))
            output.seek(0)
            return send_file(
                output,
                mimetype='application/json',
                as_attachment=True,
                download_name=f"{video_info['title'][:50]}_subtitle.json"
            )
        elif format_type == 'docx':
            docx_content = create_docx(transcript_text, video_info['title'], video_info, include_summary=True)
            return send_file(
                docx_content,
                mimetype='application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                as_attachment=True,
                download_name=f"{video_info['title'][:50]}_subtitle.docx"
            )
        else:
            return jsonify({'error': 'Unsupported format'}), 400
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

# ==================== é™æ€æ–‡ä»¶è·¯ç”± ====================
from flask import send_from_directory

@app.route('/')
def index():
    return send_from_directory('../static', 'youtube-subtitle-downloader.html')

@app.route('/<path:filename>')
def static_files(filename):
    return send_from_directory('../static', filename)

if __name__ == '__main__':
    app.run(host='0.0.0.0', debug=True, port=5002)
