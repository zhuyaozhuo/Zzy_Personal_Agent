#!/usr/bin/env python3
"""
å°†æŸ¥ç†èŠ’æ ¼æ¼”è®²å­—å¹•è½¬æ¢ä¸ºWordæ–‡æ¡£
æ”¯æŒè¯­è¨€æ ‡è®°å’Œè‡ªåŠ¨æ–­å¥
"""

import json
import os
import re
from pathlib import Path
from datetime import datetime
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn
from docx.oxml import OxmlElement


def set_chinese_font(run, font_name='SimSun', font_size=12):
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    run.font.name = font_name
    run.font.size = Pt(font_size)
    r = run._element
    rPr = r.get_or_add_rPr()
    rFonts = OxmlElement('w:rFonts')
    rFonts.set(qn('w:eastAsia'), font_name)
    rPr.insert(0, rFonts)


def detect_language(text: str) -> str:
    """æ£€æµ‹æ–‡æœ¬è¯­è¨€"""
    chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
    total_chars = len(text.replace(' ', ''))
    
    if total_chars > 0 and chinese_chars / total_chars > 0.3:
        return "ä¸­æ–‡"
    else:
        return "è‹±æ–‡"


def auto_sentence_break(text: str) -> str:
    """è‡ªåŠ¨æ–­å¥å¤„ç†"""
    text = re.sub(r'\s+', ' ', text)
    
    text = re.sub(r'([.!?])\s+', r'\1\n\n', text)
    
    text = re.sub(r'([ã€‚ï¼ï¼Ÿ])', r'\1\n\n', text)
    
    text = re.sub(r'([,ï¼Œ])\s*', r'\1 ', text)
    
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    return text.strip()


def create_word_document(video_data: dict, output_path: str):
    """åˆ›å»ºWordæ–‡æ¡£"""
    
    doc = Document()
    
    title = video_data.get('title', 'Untitled')
    language = video_data.get('language', detect_language(video_data.get('transcript', '')))
    
    doc_title = doc.add_heading(f'ã€{language}ã€‘{title}', 0)
    doc_title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    lang_para = doc.add_paragraph()
    lang_run = lang_para.add_run(f'å­—å¹•è¯­è¨€: {language}')
    lang_run.bold = True
    lang_run.font.color.rgb = RGBColor(0, 102, 204)
    lang_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    doc.add_paragraph('')
    
    info_table = doc.add_table(rows=6, cols=2)
    info_table.style = 'Table Grid'
    
    info_data = [
        ('é¢‘é“', video_data.get('channel', 'N/A')),
        ('æ’­æ”¾é‡', f"{video_data.get('view_count', 0):,}" if isinstance(video_data.get('view_count'), int) else str(video_data.get('view_count', 'N/A'))),
        ('ç‚¹èµæ•°', f"{video_data.get('like_count', 0):,}" if video_data.get('like_count') else 'N/A'),
        ('æ—¶é•¿', f"{video_data.get('duration', 0)} ç§’" if isinstance(video_data.get('duration'), int) else str(video_data.get('duration', 'N/A'))),
        ('é“¾æ¥', video_data.get('url', 'N/A')),
        ('åˆ†ææ—¥æœŸ', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    ]
    
    for i, (label, value) in enumerate(info_data):
        row = info_table.rows[i]
        row.cells[0].text = label
        row.cells[1].text = str(value)
    
    doc.add_paragraph('')
    doc.add_heading('è§†é¢‘æè¿°', level=1)
    description = video_data.get('description', 'æ— æè¿°')
    doc.add_paragraph(description[:1000] if len(description) > 1000 else description)
    
    transcript = video_data.get('transcript', '')
    if transcript:
        doc.add_page_break()
        doc.add_heading(f'å®Œæ•´å­—å¹• ({language})', level=1)
        
        processed_text = auto_sentence_break(transcript)
        
        paragraphs = processed_text.split('\n\n')
        
        for para_text in paragraphs:
            if para_text.strip():
                p = doc.add_paragraph()
                run = p.add_run(para_text.strip())
                
                if language == "ä¸­æ–‡":
                    set_chinese_font(run, 'SimSun', 12)
                else:
                    run.font.name = 'Times New Roman'
                    run.font.size = Pt(12)
                
                p.paragraph_format.first_line_indent = Pt(20)
                p.paragraph_format.space_after = Pt(8)
        
        doc.add_paragraph('')
        p = doc.add_paragraph()
        run = p.add_run(f'å­—å¹•æ€»é•¿åº¦: {len(transcript):,} å­—ç¬¦ | è¯­è¨€: {language}')
        run.italic = True
        run.font.color.rgb = RGBColor(128, 128, 128)
    
    doc.save(output_path)
    print(f"âœ… Wordæ–‡æ¡£å·²ä¿å­˜: {output_path}")
    return output_path


def main():
    print("\n" + "="*70)
    print("ğŸ“„ å°†æŸ¥ç†èŠ’æ ¼æ¼”è®²å­—å¹•è½¬æ¢ä¸ºWordæ–‡æ¡£")
    print("="*70 + "\n")
    
    output_dir = Path("data/youtube/word_documents")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    videos_with_transcript = []
    
    for i in range(1, 4):
        json_file = Path(f"data/youtube/munger_speech_{i}.json")
        if json_file.exists():
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if data.get('transcript'):
                videos_with_transcript.append((i, data))
                lang = data.get('language', detect_language(data.get('transcript', '')))
                print(f"ğŸ“¹ è§†é¢‘ {i}: {data.get('title', 'N/A')[:50]}...")
                print(f"   âœ… æœ‰å­—å¹• ({len(data.get('transcript', '')):,} å­—ç¬¦) - è¯­è¨€: {lang}")
            else:
                print(f"ğŸ“¹ è§†é¢‘ {i}: {data.get('title', 'N/A')[:50]}...")
                print(f"   âš ï¸  æ— å­—å¹•ï¼Œè·³è¿‡")
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
    
    print(f"\næ‰¾åˆ° {len(videos_with_transcript)} ä¸ªæœ‰å­—å¹•çš„è§†é¢‘")
    
    generated_files = []
    
    for i, (video_num, data) in enumerate(videos_with_transcript, 1):
        print(f"\n{'='*70}")
        print(f"ğŸ“ æ­£åœ¨å¤„ç†è§†é¢‘ {video_num}: {data.get('title', 'N/A')[:50]}...")
        
        language = data.get('language', detect_language(data.get('transcript', '')))
        
        safe_title = "".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in data.get('title', 'Untitled'))
        safe_title = safe_title[:50]
        
        output_file = output_dir / f"Charlie_Munger_Speech_{video_num}_ã€{language}ã€‘_{safe_title}.docx"
        
        created_file = create_word_document(data, str(output_file))
        generated_files.append((created_file, language))
    
    print("\n" + "="*70)
    print("âœ… è½¬æ¢å®Œæˆï¼")
    print("="*70)
    print(f"\nğŸ“ æ–‡ä»¶ä¿å­˜ä½ç½®: {output_dir.absolute()}")
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    
    for file, lang in generated_files:
        size = Path(file).stat().st_size / 1024
        print(f"   ğŸ“„ {Path(file).name} ({size:.1f} KB) - {lang}")
    
    return output_dir


if __name__ == "__main__":
    main()
