#!/usr/bin/env python3
"""
ä¸‹è½½æŸ¥ç†èŠ’æ ¼æ’­æ”¾é‡æœ€é«˜çš„5ä¸ªè§†é¢‘çš„ä¸­æ–‡å­—å¹•
"""

import asyncio
import sys
import os
import re
import json
from pathlib import Path
from datetime import datetime
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn
from docx.oxml import OxmlElement

sys.path.insert(0, str(Path(__file__).parent))

from agents.youtube_agent import YouTubeAgent
from utils.logger import logger


def set_chinese_font(run, font_name='SimSun', font_size=12):
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    run.font.name = font_name
    run.font.size = Pt(font_size)
    r = run._element
    rPr = r.get_or_add_rPr()
    rFonts = OxmlElement('w:rFonts')
    rFonts.set(qn('w:eastAsia'), font_name)
    rPr.insert(0, rFonts)


def auto_sentence_break(text: str) -> str:
    """è‡ªåŠ¨æ–­å¥å¤„ç†"""
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'([.!?])\s+', r'\1\n\n', text)
    text = re.sub(r'([ã€‚ï¼ï¼Ÿ])', r'\1\n\n', text)
    text = re.sub(r'([,ï¼Œ])\s*', r'\1 ', text)
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text.strip()


def create_word_document(video_data: dict, output_path: str, language: str):
    """åˆ›å»ºWordæ–‡æ¡£"""
    
    doc = Document()
    
    title = video_data.get('title', 'Untitled')
    
    doc_title = doc.add_heading(f'ã€{language}ã€‘{title}', 0)
    doc_title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    lang_para = doc.add_paragraph()
    lang_run = lang_para.add_run(f'å­—å¹•è¯­è¨€: {language}')
    lang_run.bold = True
    lang_run.font.color.rgb = RGBColor(0, 102, 204)
    lang_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    doc.add_paragraph('')
    
    info_table = doc.add_table(rows=6, cols=2)
    info_table.style = 'Table Grid'
    
    info_data = [
        ('é¢‘é“', video_data.get('channel', 'N/A')),
        ('æ’­æ”¾é‡', f"{video_data.get('view_count', 0):,}" if isinstance(video_data.get('view_count'), int) else str(video_data.get('view_count', 'N/A'))),
        ('ç‚¹èµæ•°', f"{video_data.get('like_count', 0):,}" if video_data.get('like_count') else 'N/A'),
        ('æ—¶é•¿', f"{video_data.get('duration', 0)} ç§’" if isinstance(video_data.get('duration'), int) else str(video_data.get('duration', 'N/A'))),
        ('é“¾æ¥', video_data.get('url', 'N/A')),
        ('åˆ†ææ—¥æœŸ', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    ]
    
    for i, (label, value) in enumerate(info_data):
        row = info_table.rows[i]
        row.cells[0].text = label
        row.cells[1].text = str(value)
    
    doc.add_paragraph('')
    doc.add_heading('è§†é¢‘æè¿°', level=1)
    description = video_data.get('description', 'æ— æè¿°')
    doc.add_paragraph(description[:1000] if len(description) > 1000 else description)
    
    transcript = video_data.get('transcript', '')
    if transcript:
        doc.add_page_break()
        doc.add_heading(f'å®Œæ•´å­—å¹• ({language})', level=1)
        
        processed_text = auto_sentence_break(transcript)
        paragraphs = processed_text.split('\n\n')
        
        for para_text in paragraphs:
            if para_text.strip():
                p = doc.add_paragraph()
                run = p.add_run(para_text.strip())
                
                if language == "ä¸­æ–‡":
                    set_chinese_font(run, 'SimSun', 12)
                else:
                    run.font.name = 'Times New Roman'
                    run.font.size = Pt(12)
                
                p.paragraph_format.first_line_indent = Pt(20)
                p.paragraph_format.space_after = Pt(8)
        
        doc.add_paragraph('')
        p = doc.add_paragraph()
        run = p.add_run(f'å­—å¹•æ€»é•¿åº¦: {len(transcript):,} å­—ç¬¦ | è¯­è¨€: {language}')
        run.italic = True
        run.font.color.rgb = RGBColor(128, 128, 128)
    
    doc.save(output_path)
    return output_path


async def download_munger_chinese_subtitles():
    """ä¸‹è½½æŸ¥ç†èŠ’æ ¼æ’­æ”¾é‡æœ€é«˜çš„5ä¸ªè§†é¢‘çš„ä¸­æ–‡å­—å¹•"""
    
    print("\n" + "="*70)
    print("ğŸ¬ ä¸‹è½½æŸ¥ç†èŠ’æ ¼æ¼”è®²è§†é¢‘ - ä¸­æ–‡å­—å¹•")
    print("="*70 + "\n")
    
    agent = YouTubeAgent()
    
    print("ğŸ“¡ æ­£åœ¨æœç´¢æŸ¥ç†èŠ’æ ¼æ¼”è®²è§†é¢‘...")
    search_result = agent._search_youtube("Charlie Munger speech", max_results=20)
    
    if not search_result.get("success"):
        print(f"âŒ æœç´¢å¤±è´¥: {search_result.get('error')}")
        return
    
    videos = search_result.get("videos", [])
    print(f"âœ… æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘\n")
    
    print("ğŸ“Š æ­£åœ¨è·å–è§†é¢‘è¯¦æƒ…å¹¶æŒ‰æ’­æ”¾é‡æ’åº...")
    videos_with_data = []
    for i, video in enumerate(videos, 1):
        print(f"   å¤„ç† {i}/{len(videos)}: {video['title'][:40]}...", end='\r')
        details_result = agent._get_video_details(video["video_id"])
        if details_result.get("success"):
            video_data = {**video, **details_result.get("details", {})}
            views = video_data.get("view_count", video_data.get("views", 0))
            if isinstance(views, str):
                views = agent._parse_views(views)
            videos_with_data.append((views, video_data))
    
    print(f"\nâœ… è·å–äº† {len(videos_with_data)} ä¸ªè§†é¢‘è¯¦æƒ…")
    
    videos_with_data.sort(key=lambda x: x[0], reverse=True)
    
    print("\n" + "="*70)
    print("ğŸ“Š æ’­æ”¾é‡æ’åå‰10çš„è§†é¢‘:")
    print("="*70)
    for i, (views, video) in enumerate(videos_with_data[:10], 1):
        print(f"   {i}. {video['title'][:50]}... ({agent._format_number(views)})")
    
    print("\n" + "="*70)
    print("ğŸ” æ­£åœ¨æ£€æŸ¥å­—å¹•å¯ç”¨æ€§å¹¶ä¸‹è½½ä¸­æ–‡å­—å¹•...")
    print("="*70)
    
    output_dir = Path("data/youtube/word_documents")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    successful_downloads = []
    attempt_count = 0
    
    for views, video in videos_with_data:
        if len(successful_downloads) >= 5:
            break
        
        attempt_count += 1
        video_id = video["video_id"]
        
        print(f"\n{'='*70}")
        print(f"ğŸ“¹ [{attempt_count}] {video['title'][:50]}...")
        print(f"   æ’­æ”¾é‡: {agent._format_number(views)}")
        print(f"   è§†é¢‘ID: {video_id}")
        
        print(f"\n   ğŸ” æ£€æŸ¥å¯ç”¨å­—å¹•è¯­è¨€...")
        lang_result = agent._list_available_transcripts(video_id)
        
        if not lang_result.get("success"):
            print(f"   âš ï¸  æ— æ³•è·å–å­—å¹•åˆ—è¡¨: {lang_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            continue
        
        available_languages = lang_result.get("languages", [])
        print(f"   ğŸ“‹ å¯ç”¨è¯­è¨€: {len(available_languages)} ç§")
        
        chinese_langs = [l for l in available_languages if l['code'] in ['zh-CN', 'zh-Hans', 'zh-TW', 'zh-Hant', 'zh']]
        
        if not chinese_langs:
            en_langs = [l for l in available_languages if l['code'].startswith('en')]
            if en_langs:
                print(f"   âš ï¸  æ— ä¸­æ–‡å­—å¹•ï¼Œå°è¯•ä½¿ç”¨è‹±æ–‡å­—å¹•...")
                lang_to_use = "en"
            else:
                print(f"   âš ï¸  æ— ä¸­æ–‡å­—å¹•æˆ–è‹±æ–‡å­—å¹•ï¼Œè·³è¿‡")
                continue
        else:
            lang_to_use = "ä¸­æ–‡"
            print(f"   âœ… æ‰¾åˆ°ä¸­æ–‡å­—å¹•: {[l['code'] for l in chinese_langs]}")
        
        print(f"\n   ğŸ“¥ æ­£åœ¨ä¸‹è½½å­—å¹• ({lang_to_use})...")
        transcript_result = agent._get_video_transcript(
            video_id, 
            language=lang_to_use,
            auto_sentence_break=True
        )
        
        if not transcript_result.get("success"):
            error = transcript_result.get("error", "æœªçŸ¥é”™è¯¯")
            print(f"   âŒ å­—å¹•ä¸‹è½½å¤±è´¥: {error}")
            continue
        
        transcript = transcript_result.get("full_text", "")
        detected_lang = transcript_result.get("language", lang_to_use)
        transcript_length = len(transcript)
        
        print(f"   âœ… å­—å¹•ä¸‹è½½æˆåŠŸï¼é•¿åº¦: {transcript_length:,} å­—ç¬¦")
        print(f"   ğŸŒ æ£€æµ‹è¯­è¨€: {detected_lang}")
        
        print(f"\n   ğŸ“„ å­—å¹•é¢„è§ˆ (å‰300å­—ç¬¦):")
        print(f"   {'-'*66}")
        preview = auto_sentence_break(transcript[:300])
        print(f"   {preview}...")
        print(f"   {'-'*66}")
        
        video["transcript"] = transcript
        video["transcript_length"] = transcript_length
        video["language"] = detected_lang
        video["view_count"] = views
        
        print(f"\n   ğŸ’¾ æ­£åœ¨è½¬æ¢ä¸ºWordæ–‡æ¡£...")
        
        safe_title = "".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in video.get('title', 'Untitled'))
        safe_title = safe_title[:50]
        
        output_file = output_dir / f"Munger_{len(successful_downloads)+1}_ã€{detected_lang}ã€‘_{safe_title}.docx"
        
        try:
            created_file = create_word_document(video, str(output_file), detected_lang)
            size = Path(created_file).stat().st_size / 1024
            print(f"   âœ… Wordæ–‡æ¡£å·²ä¿å­˜: {output_file.name} ({size:.1f} KB)")
            successful_downloads.append((created_file, detected_lang, video['title'], views))
        except Exception as e:
            print(f"   âŒ Wordè½¬æ¢å¤±è´¥: {e}")
            continue
        
        json_file = output_dir.parent / f"video_{video_id}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(video, f, ensure_ascii=False, indent=2)
        print(f"   ğŸ“„ JSONæ•°æ®å·²ä¿å­˜: {json_file.name}")
    
    print("\n" + "="*70)
    print("âœ… ä»»åŠ¡å®Œæˆï¼")
    print("="*70)
    
    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"   - æ£€æŸ¥è§†é¢‘æ•°: {attempt_count}")
    print(f"   - æˆåŠŸä¸‹è½½æ•°: {len(successful_downloads)}")
    
    print(f"\nğŸ“ æ–‡ä»¶ä¿å­˜ä½ç½®: {output_dir.absolute()}")
    
    if successful_downloads:
        print("\nğŸ“„ ç”Ÿæˆçš„Wordæ–‡æ¡£:")
        for i, (file, lang, title, views) in enumerate(successful_downloads, 1):
            size = Path(file).stat().st_size / 1024
            print(f"\n   {i}. {Path(file).name}")
            print(f"      æ ‡é¢˜: {title[:50]}...")
            print(f"      è¯­è¨€: {lang} | å¤§å°: {size:.1f} KB | æ’­æ”¾é‡: {agent._format_number(views)}")
    
    return successful_downloads


if __name__ == "__main__":
    asyncio.run(download_munger_chinese_subtitles())
